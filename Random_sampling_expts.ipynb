{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from ferm import FERM\n",
    "from ferm_mt import FERM_MT\n",
    "from data_loader import load_dataset\n",
    "from sklearn.utils import resample\n",
    "\n",
    "np.random.seed(912)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading arrhythmia dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zfs/aponlab/users/akulshr/fairness_ml/fair_ERM/data_loader.py:49: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df.colums = [i for i in range(279)]\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1.0],\n",
    "    'kernel': ['rbf']\n",
    "}]\n",
    "\n",
    "dtrain, dtest, sf = load_dataset('arrhythm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack([dtrain.data, dtest.data])\n",
    "target = np.hstack([dtrain.target, dtest.target])\n",
    "sens = np.hstack([dtrain.sens, dtest.sens])\n",
    "\n",
    "id_y1 = target == 1.0\n",
    "id_ny1 = target == -1.0\n",
    "\n",
    "data_y1 = data[id_y1]\n",
    "data_ny1 = data[id_ny1]\n",
    "y1 = target[id_y1]\n",
    "ny1 = target[id_ny1]\n",
    "\n",
    "ny1_ds = resample(ny1, replace=True, n_samples=y1.shape[0], random_state=912)\n",
    "data_ny1_ds = resample(data_ny1, replace=True, n_samples=y1.shape[0], random_state=912)\n",
    "\n",
    "data_n = np.vstack([data_y1, data_ny1_ds])\n",
    "target_n = np.hstack([y1, ny1_ds])\n",
    "sens_n = resample(sens, replace=True, n_samples=target_n.shape[0], random_state=912)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def job_fn(model, data, target, sens, param_grid, split=0.8):\n",
    "    '''\n",
    "    Run job in parallel on diff random sets \n",
    "    and get fpr, tpr etc on the values. Sensitive \n",
    "    group agnostic permutations.\n",
    "    '''\n",
    "    perm = np.random.permutation(data.shape[0])\n",
    "    ntrain = int(data.shape[0]*split)\n",
    "    data, target, sens = data[perm], target[perm], sens[perm]\n",
    "    X_train, y_train, sens_train = data[:ntrain, :], target[:ntrain], sens[:ntrain]\n",
    "    X_test, y_test, sens_test = data[ntrain:, :], target[ntrain:], sens[ntrain:]\n",
    "    clf = GridSearchCV(model, param_grid)\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "    tpr = tp / (tp + fp)\n",
    "    fpr = fp / (fp + tn)\n",
    "    gt_0, gt_1 = y_test[sens_test == 0], y_test[sens_test == 1]\n",
    "    p_0, p_1 = pred[sens_test == 0], pred[sens_test==1]\n",
    "    tn_0, fp_0, fn_0, tp_0 = confusion_matrix(gt_0, p_0).ravel()\n",
    "    tn_1, fp_1, fn_1, tp_1 = confusion_matrix(gt_1, p_1).ravel()\n",
    "    fpr_sens = {'0': fp_0 / (fp_0 + tn_0), '1': fp_1 / (fp_1 + tn_1)}\n",
    "    tpr_sens = {'0': tp_0 / (tp_0 + fp_0), '1': tp_1 / (tp_1 + fp_1)}\n",
    "    return acc, tpr, fpr, tpr_sens, fpr_sens\n",
    "\n",
    "\n",
    "def get_results(res):\n",
    "    acc = np.array([r[0] for r in res])\n",
    "    tpr = np.array([r[1] for r in res])\n",
    "    fpr = np.array([r[2] for r in res])\n",
    "    tpr_sens_0 = np.array([r[3]['0'] for r in res])\n",
    "    tpr_sens_1 = np.array([r[3]['1'] for r in res])\n",
    "    fpr_sens_0 = np.array([r[4]['0'] for r in res])\n",
    "    fpr_sens_1 = np.array([r[4]['1'] for r in res])\n",
    "    \n",
    "    print(f'acc: {np.mean(acc)} ± {np.std(acc)}')\n",
    "    print(f'TPR: {np.mean(tpr)} ± {np.std(tpr)}')\n",
    "    print(f'dFPR: {np.mean(np.abs(fpr_sens_0 - fpr_sens_1))} ± {np.std(np.abs(fpr_sens_0 - fpr_sens_1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC()\n",
    "res = Parallel(n_jobs=8)([delayed(job_fn)(svc, data, target, sens, param_grid) for _ in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.6976127320954907 ± 0.018756148042083472\n",
      "TPR: 0.6728084727678224 ± 0.018810578050465116\n",
      "dFPR: 0.12690230625411061 ± 0.08754575554499024\n"
     ]
    }
   ],
   "source": [
    "get_results(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = FERM_MT(sensible_feature=sens_n, rho=0.1)\n",
    "res1 = Parallel(n_jobs=16)([delayed(job_fn)(fmt, data, target, sens, param_grid) for _ in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.6944297082228117 ± 0.011051812549601962\n",
      "TPR: 0.661987073926553 ± 0.03294750101954578\n",
      "dFPR: 0.07449569629941082 ± 0.04708200449115961\n"
     ]
    }
   ],
   "source": [
    "get_results(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ferm = FERM(sensible_feature=sens_n)\n",
    "res2 = Parallel(n_jobs=16)([delayed(job_fn)(ferm, data, target, sens, param_grid) for _ in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.6870026525198939 ± 0.017833141977688715\n",
      "TPR: 0.6483849263409208 ± 0.017989104731772027\n",
      "dFPR: 0.08537689607738352 ± 0.035846356385355244\n"
     ]
    }
   ],
   "source": [
    "get_results(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((490, 278), (490,), (490,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_n.shape, target_n.shape, sens_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0306965761511218,\n",
       " 0.1936245572609209,\n",
       " 1.6586306653809064,\n",
       " 0.15814850530376084)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = (sens == 1).sum()/target[id_y1].shape[0]\n",
    "s2 = (sens == 0).sum()/target[id_y1].shape[0]\n",
    "s1n = (sens == 1).sum()/target[id_ny1].shape[0]\n",
    "s2n = (sens == 0).sum()/target[id_ny1].shape[0]\n",
    "s1, s2, s1n, s2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 85)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sens[id_y1] == 1).sum(), (sens[id_y1] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 117)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sens[id_ny1] == 1).sum(),(sens[id_ny1] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(agatha)",
   "language": "python",
   "name": "agatha"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
